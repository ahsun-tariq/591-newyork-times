{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f248a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsun/.local/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ahsun/.local/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ahsun/.local/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ahsun/.local/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "# import nwhy\n",
    "import hypernetx as hnx\n",
    "import networkx as nx\n",
    "from networkx import Graph\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8968f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./archive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b3175e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[43mpath\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_articles = []\n",
    "paths_comments = []\n",
    "\n",
    "articles_file_path_jan = path + '/' +'ArticlesJan2018.csv'\n",
    "paths_articles.append(articles_file_path_jan)\n",
    "comments_file_path_jan = path + '/' + 'CommentsJan2018.csv'\n",
    "paths_comments.append(comments_file_path_jan)\n",
    "\n",
    "articles_file_path_feb = path + '/' +'ArticlesFeb2018.csv'\n",
    "paths_articles.append(articles_file_path_feb)\n",
    "comments_file_path_feb = path + '/' + 'CommentsFeb2018.csv'\n",
    "paths_comments.append(comments_file_path_feb)\n",
    "\n",
    "\n",
    "articles_file_path_march = path + '/' +'ArticlesMarch2018.csv'\n",
    "paths_articles.append(articles_file_path_march)\n",
    "comments_file_path_march = path + '/' + 'CommentsMarch2018.csv'\n",
    "paths_comments.append(comments_file_path_march)\n",
    "\n",
    "articles_file_path_april = path + '/' +'ArticlesApril2018.csv'\n",
    "# paths_articles.append(articles_file_path_april)\n",
    "comments_file_path_april = path + '/' + 'CommentsApril2018.csv'\n",
    "# paths_comments.append(comments_file_path_april)\n",
    "\n",
    "print(paths_articles)\n",
    "print(paths_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb40aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMax(dictionary):\n",
    "    mx = 0\n",
    "    max_key = -1\n",
    "    for key in dictionary:\n",
    "        if dictionary[key] > mx:\n",
    "            mx = dictionary[key] \n",
    "            max_key = key\n",
    "    return (max_key,mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c0bb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMin(dictionary):\n",
    "    mn = 1\n",
    "    min_key = -1\n",
    "    for key in dictionary:\n",
    "        if dictionary[key] < mn:\n",
    "            mn = dictionary[key] \n",
    "            min_key = key\n",
    "    return (min_key,mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb1c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGraphAsDict(G, filename):\n",
    "    dictionary = nx.to_dict_of_dicts(G)\n",
    "    files = os.listdir()\n",
    "    if not filename in files:\n",
    "        with open(filename, 'wb') as f:\n",
    "            print(f'dumping articles into {filename}...')\n",
    "            pickle.dump(dictionary, f)\n",
    "    else:\n",
    "        print(\"file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9595a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphFromDict(filename):\n",
    "    files = os.listdir()\n",
    "    if filename in files:\n",
    "        with open(filename, \"rb\") as f:\n",
    "            dictionary = pickle.load(f)\n",
    "            print(f'loaded dictionary from {filename}, length is {len(dictionary)}')\n",
    "            G = from_dict_of_dicts(dictionary)\n",
    "            return G\n",
    "    else:\n",
    "        print(\"no such file\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363be082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDictionary(array_of_dictionaries):\n",
    "    dictionary = array_of_dictionaries[0]\n",
    "    for i in range(1, len(array_of_dictionaries)):\n",
    "        dictionary.update(array_of_dictionaries[i])\n",
    "    return dictionary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2782ee29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m articles  \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m articles_file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpaths_articles\u001b[49m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(articles_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m,newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m         csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paths_articles' is not defined"
     ]
    }
   ],
   "source": [
    "articles  = {}\n",
    "count = 0\n",
    "for articles_file_path in paths_articles:\n",
    "\n",
    "    with open(articles_file_path, \"r\",encoding=\"utf-8\",newline=\"\") as f:\n",
    "        csv_reader = csv.reader(f, delimiter=\",\")\n",
    "        header = next(csv_reader)\n",
    "        record = [{field:None} for field in header]\n",
    "        index = 0\n",
    "        for i,item in enumerate(record):\n",
    "            if(list(item.keys())[0]) == \"articleID\":\n",
    "                index =i\n",
    "        for row in csv_reader:\n",
    "            record = [{field:None} for field in header]\n",
    "            for i, item in enumerate(row):\n",
    "                record[i][list(record[i].keys())[0]] = item\n",
    "            articles[row[index]]= createDictionary(record)\n",
    "            count += 1\n",
    "print(count)\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60040179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded articles from articles.pickle..\n",
      "3445\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir()\n",
    "if not \"articles.pickle\" in files:\n",
    "    with open('articles.pickle', 'wb') as f:\n",
    "        print(\"dumping articles into articles.pickle....\")\n",
    "        pickle.dump(articles, f)\n",
    "else:\n",
    "    with open(\"articles.pickle\", \"rb\") as f:\n",
    "        print(\"loaded articles from articles.pickle..\")\n",
    "        articles = pickle.load(f)\n",
    "print(len(articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for ID in articles:\n",
    "    print(ID)\n",
    "    print(articles[ID])\n",
    "    count +=1\n",
    "    if count==5:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = {}\n",
    "num = 0\n",
    "for comments_file_path in paths_comments:\n",
    "    with open(comments_file_path, \"r\",encoding=\"utf-8\",newline=\"\") as f:\n",
    "        csv_reader = csv.reader(f, delimiter=\",\")\n",
    "        header = next(csv_reader)\n",
    "        record = [{field:None} for field in header]\n",
    "        index = 4\n",
    "        for i,item in enumerate(record):\n",
    "            if(list(item.keys())[0]) == \"commentID\":\n",
    "                index =i\n",
    "        for row in csv_reader:\n",
    "            num+=1\n",
    "            record = [{field:None} for field in header]\n",
    "            for i, item in enumerate(row):\n",
    "                record[i][list(record[i].keys())[0]] = item\n",
    "            dictionary = createDictionary(record)\n",
    "            if dictionary[\"articleID\"] in articles.keys():\n",
    "                comments[str(row[index])] = dictionary\n",
    "            \n",
    "print(num)\n",
    "print(f'total comments: {len(comments)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84c9415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded comments from comments.pickle..\n",
      "640904\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir()\n",
    "if not \"comments.pickle\" in files:\n",
    "    with open('comments.pickle', 'wb') as f:\n",
    "        print(\"dumping comments into comments.pickle....\")\n",
    "        pickle.dump(comments, f)\n",
    "else:\n",
    "    with open(\"comments.pickle\", \"rb\") as f:\n",
    "        print(\"loaded comments from comments.pickle..\")\n",
    "        comments = pickle.load(f)\n",
    "        \n",
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for ID in comments:\n",
    "    print(ID)\n",
    "    print(comments[ID])\n",
    "    count +=1\n",
    "    if count==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for commentID in comments:\n",
    "    articleID = comments[commentID][\"articleID\"] \n",
    "    if not \"num_comments\" in articles[articleID]:\n",
    "        articles[articleID][\"num_comments\"] = 1\n",
    "    else:\n",
    "        articles[articleID][\"num_comments\"] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94456e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for ID in articles:\n",
    "    print(articles[ID])\n",
    "    count +=1\n",
    "    if count==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comments = 0\n",
    "article_with_most_comments = {}\n",
    "maxnum = 0\n",
    "for articleID in articles:\n",
    "    total_comments += articles[articleID][\"num_comments\"]\n",
    "    if articles[articleID][\"num_comments\"] > maxnum:\n",
    "        maxnum = articles[articleID][\"num_comments\"]\n",
    "        article_with_most_comments = articles[articleID]\n",
    "print(total_comments)\n",
    "print(article_with_most_comments)\n",
    "print(maxnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a55789",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_to_commenters = {articles[ID][\"articleID\"]:set({}) for ID in articles}\n",
    "users = {}\n",
    "for ID in comments:\n",
    "    articleID = comments[ID][\"articleID\"]\n",
    "    userID = comments[ID][\"userID\"]\n",
    "    userTitle  = \"unknown\"\n",
    "    userLocation = \"unknown\"\n",
    "    if \"userTitle\" in comments[ID].keys():\n",
    "        userTitle = comments[ID][\"userTitle\"]\n",
    "    if \"userLocation\" in comments[ID].keys():\n",
    "        userLocation = comments[ID][\"userLocation\"]\n",
    "        \n",
    "    users[userID] = {\"userTitle\":userTitle, \"location\":userLocation}    \n",
    "    articles_to_commenters[articleID].add(userID)\n",
    "    \n",
    "\n",
    "    \n",
    "print(f'{len(users)} users found')\n",
    "\n",
    "for i, ID in enumerate(users):\n",
    "    print(ID)\n",
    "    print(users[ID])\n",
    "    if i==5:\n",
    "        break\n",
    "\n",
    "for i, ID in enumerate(articles_to_commenters):\n",
    "    print(ID)\n",
    "    print(articles_to_commenters[ID])\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c71dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded users from users.pickle..\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir()\n",
    "if not \"users.pickle\" in files:\n",
    "    with open('users.pickle', 'wb') as f:\n",
    "        print(\"dumping users into users.pickle....\")\n",
    "        pickle.dump(users, f)\n",
    "else:\n",
    "    with open(\"users.pickle\", \"rb\") as f:\n",
    "        print(\"loaded users from users.pickle..\")\n",
    "        users = pickle.load(f)\n",
    "print(type(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38607cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded articles_to_commenters from articles_to_commenters.pickle..\n",
      "3445\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir()\n",
    "if not \"articles_to_commenters.pickle\" in files:\n",
    "    with open('articles_to_commenters.pickle', 'wb') as f:\n",
    "        print(\"dumping articles_to_commenters into articles_to_commenters.pickle....\")\n",
    "        pickle.dump(articles_to_commenters, f)\n",
    "else:\n",
    "    with open(\"articles_to_commenters.pickle\", \"rb\") as f:\n",
    "        print(\"loaded articles_to_commenters from articles_to_commenters.pickle..\")\n",
    "        articles_to_commenters = pickle.load(f)\n",
    "print(len(articles_to_commenters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c175dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hnx.Entity('a',{1,2})\n",
    "b = hnx.Entity('b',{2,3})\n",
    "c = hnx.Entity('c',{1,3})\n",
    "E = hnx.EntitySet('sample',elements=[a,b,c])\n",
    "H =hnx.Hypergraph(E, static = True)\n",
    "hnx.Hypergraph(E)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.Hypergraph(E).edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2463f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hnx.drawing.rubber_band.draw(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linegraph = H.get_linegraph(1, edges=True, use_nwhy=True)\n",
    "nx.draw(linegraph,with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b845f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'articles_to_commenters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m entities \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m articleID \u001b[38;5;129;01min\u001b[39;00m \u001b[43marticles_to_commenters\u001b[49m:\n\u001b[1;32m      3\u001b[0m     entities\u001b[38;5;241m.\u001b[39mappend(hnx\u001b[38;5;241m.\u001b[39mEntity(articleID,articles_to_commenters[articleID]))\n\u001b[1;32m      5\u001b[0m E \u001b[38;5;241m=\u001b[39m hnx\u001b[38;5;241m.\u001b[39mEntitySet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticles_commenters\u001b[39m\u001b[38;5;124m'\u001b[39m,elements\u001b[38;5;241m=\u001b[39mentities)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'articles_to_commenters' is not defined"
     ]
    }
   ],
   "source": [
    "entities = []\n",
    "for articleID in articles_to_commenters:\n",
    "    entities.append(hnx.Entity(articleID,articles_to_commenters[articleID]))\n",
    "    \n",
    "E = hnx.EntitySet('articles_commenters',elements=entities)\n",
    "H = hnx.Hypergraph(E,static=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ddda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linegraph = H.get_linegraph(1, edges=True, use_nwhy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hnx.drawing.rubber_band.draw(H)\n",
    "# nx.draw(linegraph,with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64431f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(linegraph.edges)\n",
    "# print(edges[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ca9652",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'articles_to_commenters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m articles_one_commenter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m167\u001b[39m, \u001b[38;5;241m1480\u001b[39m,\u001b[38;5;241m2408\u001b[39m,\u001b[38;5;241m1717\u001b[39m,\u001b[38;5;241m414\u001b[39m,\u001b[38;5;241m702\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ID \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43marticles_to_commenters\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m articles_one_commenter:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, snippet:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticles[ID][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, commenter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticles_to_commenters[ID]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'articles_to_commenters' is not defined"
     ]
    }
   ],
   "source": [
    "articles_one_commenter = [167, 1480,2408,1717,414,702]\n",
    "for i, ID in enumerate(articles_to_commenters):\n",
    "    if i in articles_one_commenter:\n",
    "        print(f'article:{ID}, snippet:{articles[ID][\"snippet\"]}, commenter: {articles_to_commenters[ID]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9340b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set()\n",
    "for item in users:    \n",
    "    place = users[item]['location']\n",
    "    if ',' in place:\n",
    "        locations.add(place)\n",
    "# locations_to_users = {:set({}) for ID in articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679fd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsNumber(value):\n",
    "    if True in [char.isdigit() for char in value]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80241eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'approveDate': '1519852022', 'articleID': '5a7101c110f40f00018be961', 'articleWordCount': '1322', 'commentBody': 'I typically strongly dislike articles which bring up such tiny disadvantages to women. But this article I liked. It mentioned, “with many female politicians being replaced by male lawmakers who have pushed for legislation to limit women’s access to abortion,” which would normally tick my non-feminist self off in a regular old article, but I feel as though the beating of their drums are beating a new perspective in my heart. The Bahia group is going against cultural norms by becoming the “first all-female bloco-afro in Brazil” and that problem was certainly not tiny. They are drumming for their rights as women. They are drumming for their rights of their race. This article has influenced me to stand for any matter I want to defend with determination just as these women did in Banda Dida.', 'commentID': '26156416.0', 'commentSequence': '26156416.0', 'commentTitle': '<br/>', 'commentType': 'comment', 'createDate': '1519849555', 'depth': '1.0', 'editorsSelection': 'False', 'inReplyTo': '0', 'newDesk': 'Travel', 'parentID': '0.0', 'parentUserDisplayName': '', 'permID': '26156416', 'picURL': 'https://graphics8.nytimes.com/images/apps/timespeople/none.png', 'printPage': '5', 'recommendations': '1', 'recommendedFlag': '', 'replyCount': '0', 'reportAbuseFlag': '', 'sectionName': 'Unknown', 'sharing': '0', 'status': 'approved', 'timespeople': '0', 'trusted': '0', 'typeOfMaterial': 'News', 'updateDate': '1519852022', 'userDisplayName': 'Emma Claire Lisk', 'userID': '83288014.0', 'userLocation': 'Wilmington, NC', 'userTitle': '', 'userURL': ''}\n",
      "{'approveDate': '1518469135', 'articleID': '5a7101c110f40f00018be961', 'articleWordCount': '1322', 'commentBody': \"I went to Cuba twice in 1998-9 to study Afro-Cuban drumming.  I am a woman.  I didn't experience any prejudice--I suppose money silences that--but we also visited Matanzas, where we listened to stellar drummers in the home of a woman who was the leader of the group.  Unusual, not unheard of.\", 'commentID': '25930059.0', 'commentSequence': '25930059.0', 'commentTitle': '<br/>', 'commentType': 'comment', 'createDate': '1518458548', 'depth': '1.0', 'editorsSelection': 'False', 'inReplyTo': '0', 'newDesk': 'Travel', 'parentID': '0.0', 'parentUserDisplayName': '', 'permID': '25930059', 'picURL': 'https://graphics8.nytimes.com/images/apps/timespeople/none.png', 'printPage': '5', 'recommendations': '0', 'recommendedFlag': '', 'replyCount': '0', 'reportAbuseFlag': '', 'sectionName': 'Unknown', 'sharing': '0', 'status': 'approved', 'timespeople': '1', 'trusted': '0', 'typeOfMaterial': 'News', 'updateDate': '1518469135', 'userDisplayName': 'Eyes Open', 'userID': '53167641.0', 'userLocation': 'San Francisco', 'userTitle': '', 'userURL': ''}\n",
      "{'approveDate': '1518385379', 'articleID': '5a7101c110f40f00018be961', 'articleWordCount': '1322', 'commentBody': 'I don\\'t think this is really all that new: I was in Salvador, Brasil in August 2013.  There was an all female drumming group that performed near the Pelourinho that blew the crowd away with their energy and skill.  Perhaps it wasn\\'t \"Dida\" that I saw, but it was a large organized group of women drummers.', 'commentID': '25912292.0', 'commentSequence': '25912292.0', 'commentTitle': '<br/>', 'commentType': 'comment', 'createDate': '1518304930', 'depth': '1.0', 'editorsSelection': 'False', 'inReplyTo': '0', 'newDesk': 'Travel', 'parentID': '0.0', 'parentUserDisplayName': '', 'permID': '25912292', 'picURL': 'https://graphics8.nytimes.com/images/apps/timespeople/none.png', 'printPage': '5', 'recommendations': '1', 'recommendedFlag': '', 'replyCount': '1', 'reportAbuseFlag': '', 'sectionName': 'Unknown', 'sharing': '1', 'status': 'approved', 'timespeople': '1', 'trusted': '0', 'typeOfMaterial': 'News', 'updateDate': '1518385379', 'userDisplayName': 'Mark Pepp', 'userID': '44043675.0', 'userLocation': 'Chicago', 'userTitle': '', 'userURL': ''}\n",
      "{'approveDate': '1517986719', 'articleID': '5a7101c110f40f00018be961', 'articleWordCount': '1322', 'commentBody': 'I was in Salvador last month and got to see Dida before attending the ballet show in pelourinho. THEY ARE AMAZING and I’m excited to return and go to one of their performances. I’ve always admired female drummers.', 'commentID': '25864174.0', 'commentSequence': '25864174.0', 'commentTitle': '<br/>', 'commentType': 'comment', 'createDate': '1517980671', 'depth': '1.0', 'editorsSelection': 'False', 'inReplyTo': '0', 'newDesk': 'Travel', 'parentID': '0.0', 'parentUserDisplayName': '', 'permID': '25864174', 'picURL': 'https://graphics8.nytimes.com/images/apps/timespeople/none.png', 'printPage': '5', 'recommendations': '0', 'recommendedFlag': '', 'replyCount': '0', 'reportAbuseFlag': '', 'sectionName': 'Unknown', 'sharing': '0', 'status': 'approved', 'timespeople': '0', 'trusted': '0', 'typeOfMaterial': 'News', 'updateDate': '1517986719', 'userDisplayName': 'Devonta', 'userID': '84748907.0', 'userLocation': 'New York, NY', 'userTitle': '', 'userURL': ''}\n",
      "{'approveDate': '1517945037', 'articleID': '5a7101c110f40f00018be961', 'articleWordCount': '1322', 'commentBody': \"Why is it that men take it upon themselves to (try to) determine where and in what capacity women can exist?  Listen up men, we've had enough of your controlling behavior and we're not going to take it any more.  Time's up!\", 'commentID': '25855991.0', 'commentSequence': '25855991.0', 'commentTitle': '<br/>', 'commentType': 'comment', 'createDate': '1517938058', 'depth': '1.0', 'editorsSelection': 'False', 'inReplyTo': '0', 'newDesk': 'Travel', 'parentID': '0.0', 'parentUserDisplayName': '', 'permID': '25855991', 'picURL': 'https://graphics8.nytimes.com/images/apps/timespeople/none.png', 'printPage': '5', 'recommendations': '12', 'recommendedFlag': '', 'replyCount': '0', 'reportAbuseFlag': '', 'sectionName': 'Unknown', 'sharing': '0', 'status': 'approved', 'timespeople': '1', 'trusted': '0', 'typeOfMaterial': 'News', 'updateDate': '1517945037', 'userDisplayName': 'EDC', 'userID': '25854823.0', 'userLocation': 'Colorado', 'userTitle': '', 'userURL': ''}\n"
     ]
    }
   ],
   "source": [
    "print(type(comments))\n",
    "i = 0\n",
    "for item in comments:\n",
    "    print(comments[item])\n",
    "    i+=1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dfad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_users = {location:set({}) for location in locations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85000a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164074\n"
     ]
    }
   ],
   "source": [
    "articleIDs = set()\n",
    "current_locations = []\n",
    "for ID in comments:\n",
    "    articleID = comments[ID][\"articleID\"]\n",
    "    split_str = articles[articleID]['keywords'].replace('\\'','').replace('[','').replace(']','')\n",
    "#     print(split_str)\n",
    "    string_array = set(split_str.split(','))\n",
    "#     print(string_array)\n",
    "#     print(comments[ID][\"userLocation\"])\n",
    "#     break\n",
    "    if comments[ID][\"userLocation\"] in locations:\n",
    "        locations_to_users[comments[ID][\"userLocation\"]] = locations_to_users[comments[ID][\"userLocation\"]].union(string_array)\n",
    "        current_locations.append(comments[ID][\"userLocation\"])\n",
    "        \n",
    "print(len(current_locations))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba863b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "i = 999\n",
    "for item in locations_to_users:\n",
    "    if i > len(locations_to_users[item]) and len(locations_to_users[item]) != 0:\n",
    "        i = len(locations_to_users[item])\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db63f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_topics = locations_to_users\n",
    "entities_of_location_graph = []\n",
    "for location in locations_to_topics:\n",
    "    entities_of_location_graph.append(hnx.Entity(location,locations_to_topics[location]))\n",
    "    \n",
    "E = hnx.EntitySet('location_topics',elements=entities_of_location_graph)\n",
    "H = hnx.Hypergraph(E,static=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047792cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_locations = hnx.Hypergraph(E).edges\n",
    "id_to_node_locations = {}\n",
    "for i, thing in enumerate(edges_locations):\n",
    "    id_to_node_locations[i] = thing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0253237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded id_to_node_locations from id_to_node_locations.pickle..\n",
      "10827\n"
     ]
    }
   ],
   "source": [
    "id_to_node_locations = {}\n",
    "files = os.listdir()\n",
    "if not \"id_to_node_locations.pickle\" in files:\n",
    "    with open('id_to_node_locations.pickle', 'wb') as f:\n",
    "        print(\"dumping id_to_node_locations into id_to_node_locations.pickle....\")\n",
    "        pickle.dump(id_to_node_locations, f)\n",
    "else:\n",
    "    with open(\"id_to_node_locations.pickle\", \"rb\") as f:\n",
    "        print(\"loaded id_to_node_locations from id_to_node_locations.pickle..\")\n",
    "        id_to_node_locations = pickle.load(f)\n",
    "print(len(id_to_node_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c8f7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "linegraph = H.get_linegraph(1, edges=True, use_nwhy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveGraphAsDict(linegraph, \"locations_and_keywords.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linegraph = getGraphFromDict(\"locations_and_keywords.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d2366b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx.draw(linegraph,with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad83ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linegraph_s4 = H.get_linegraph(4, edges=True, use_nwhy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fefecd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560/2998398286.py:1: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  pagerank_location = nx.pagerank_numpy(linegraph)\n",
      "/home/ahsun/.local/lib/python3.9/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    }
   ],
   "source": [
    "pagerank_location = nx.pagerank_numpy(linegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08c4647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560/143707583.py:1: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  pagerank_location_s4 = nx.pagerank_numpy(linegraph_s4)\n"
     ]
    }
   ],
   "source": [
    "pagerank_location_s4 = nx.pagerank_numpy(linegraph_s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pagerank_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eac6245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10827\n"
     ]
    }
   ],
   "source": [
    "print(len(pagerank_location_s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5be456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10598 0.00020668829363645373\n"
     ]
    }
   ],
   "source": [
    "max_key = max(pagerank_location, key=pagerank_location.get)\n",
    "print(max_key, pagerank_location[max_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_to_node_locations[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ef60e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10598, 0.00020668829363645373)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findMax(pagerank_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b793398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5957, 0.0006360636958491468)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findMax(pagerank_location_s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48bb0159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTA, Ontario, Canada\n"
     ]
    }
   ],
   "source": [
    "print(id_to_node_locations[10272])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea89d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pagerank_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835fad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = set()\n",
    "for ID in articles:\n",
    "    byline = articles[ID]['byline']\n",
    "    names = byline[3:].lower() \n",
    "    if ',' or 'and' in names:\n",
    "        names = set(re.split(', | and ', names))\n",
    "    authors = authors.union(names)\n",
    "        \n",
    "print(len(authors))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"by Akshaya Venkatesh, Deep Kiran and Aish Sharma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bf67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcfc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ''\n",
    "names = a[3:]\n",
    "print(names)\n",
    "names = names.lower()    \n",
    "if ',' or 'and' in names:\n",
    "    names = re.split(', | and ', names)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a52198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
